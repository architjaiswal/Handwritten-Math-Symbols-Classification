{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efd5561",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b9c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6a175e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08be418",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776f308",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80e764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_npy = np.load('data_train_correct.npy')\n",
    "label = np.load('labels_train_corrected.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae18e963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d4dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0efc0",
   "metadata": {},
   "source": [
    "VGG16 only takes images in 3 channels, so I need to convert npy data to 300X300 and then duplicate the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa170e",
   "metadata": {},
   "source": [
    "temp_image = img_npy[:,0].reshape((300,300))\n",
    "temp_image = np.expand_dims(temp_image,-1)\n",
    "temp_image_3_channel = temp_image.repeat(3,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb35501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dimensions = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ab845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img_npy.shape[1]):\n",
    "    temp_image = img_npy[:,i].reshape((300,300))\n",
    "    temp_image = np.expand_dims(temp_image,-1)\n",
    "    temp_image_3_channel = temp_image.repeat(3,axis=-1)\n",
    "    resized_img = cv2.resize(src=temp_image_3_channel, dsize=new_dimensions, interpolation=cv2.INTER_LINEAR)\n",
    "    train_img.append(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32042c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.array(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882d51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = preprocess_input(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86331099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, label_train, label_valid = train_test_split(train_img, label, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a368c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_valid = X_valid/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f27718",
   "metadata": {},
   "source": [
    "model.predict() breaks as it tries to share some work between CPU and GPU. So it needs to be executed on either 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d1b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0', '/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "GPU_names = get_available_devices()\n",
    "print(GPU_names)\n",
    "#with tf.device('/gpu:0'):\n",
    "    # Do GPU stuff here\n",
    "#with tf.device('/cpu:0'):\n",
    "    # Do CPU stuff here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c12994",
   "metadata": {},
   "source": [
    "# Extracting features from the train dataset using the VGG16 pre-trained model\n",
    "with tf.device('/cpu:0'):\n",
    "    features_train=model.predict(train_img, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9465f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape = (new_dimensions[0],new_dimensions[1],3), pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f09a7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(11,activation='softmax')(class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e58686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450adcfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 15,251,275\n",
      "Trainable params: 15,251,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fba07aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting first 8 layers to non-trianable\n",
    "\n",
    "for layer in new_model.layers[:8]:\n",
    "\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0aefc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate is changed to 0.001\n",
    "sgd = SGD(learning_rate=0.002, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "new_model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#new_model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047b388",
   "metadata": {},
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    history = new_model.fit(X_train, label_train, epochs=5, batch_size=64, validation_data=(X_valid, label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e67f1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "396/396 [==============================] - 27s 59ms/step - loss: 0.5093 - accuracy: 0.8532 - val_loss: 0.2827 - val_accuracy: 0.9181\n",
      "Epoch 2/20\n",
      "396/396 [==============================] - 22s 56ms/step - loss: 0.2337 - accuracy: 0.9345 - val_loss: 0.3902 - val_accuracy: 0.8720\n",
      "Epoch 3/20\n",
      "396/396 [==============================] - 22s 56ms/step - loss: 0.1739 - accuracy: 0.9499 - val_loss: 0.2392 - val_accuracy: 0.9317\n",
      "Epoch 4/20\n",
      "396/396 [==============================] - 22s 56ms/step - loss: 0.1161 - accuracy: 0.9668 - val_loss: 0.2305 - val_accuracy: 0.9358\n",
      "Epoch 5/20\n",
      "396/396 [==============================] - 22s 57ms/step - loss: 0.0846 - accuracy: 0.9733 - val_loss: 0.2294 - val_accuracy: 0.9387\n",
      "Epoch 6/20\n",
      "396/396 [==============================] - 22s 57ms/step - loss: 0.0757 - accuracy: 0.9764 - val_loss: 0.2444 - val_accuracy: 0.9384\n",
      "Epoch 7/20\n",
      "396/396 [==============================] - 23s 57ms/step - loss: 0.0550 - accuracy: 0.9845 - val_loss: 0.2311 - val_accuracy: 0.9458\n",
      "Epoch 8/20\n",
      "396/396 [==============================] - 23s 57ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.2601 - val_accuracy: 0.9494\n",
      "Epoch 9/20\n",
      "396/396 [==============================] - 23s 57ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.2634 - val_accuracy: 0.9465\n",
      "Epoch 10/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.3395 - val_accuracy: 0.9177\n",
      "Epoch 11/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.3496 - val_accuracy: 0.9277\n",
      "Epoch 12/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0463 - accuracy: 0.9854 - val_loss: 0.3347 - val_accuracy: 0.9288\n",
      "Epoch 13/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.3813 - val_accuracy: 0.9365\n",
      "Epoch 14/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.3051 - val_accuracy: 0.9517\n",
      "Epoch 15/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.2588 - val_accuracy: 0.9487\n",
      "Epoch 16/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.2715 - val_accuracy: 0.9513\n",
      "Epoch 17/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.2853 - val_accuracy: 0.9491\n",
      "Epoch 18/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.3180 - val_accuracy: 0.9517\n",
      "Epoch 19/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.3214 - val_accuracy: 0.9513\n",
      "Epoch 20/20\n",
      "396/396 [==============================] - 23s 58ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.3236 - val_accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = new_model.fit(X_train, label_train, epochs=20, batch_size=16, validation_data=(X_valid, label_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97858ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
